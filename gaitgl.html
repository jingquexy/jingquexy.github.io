<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>gaitgl.py</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <style>
        body { margin: 0; padding: 20px; background: #2d2d2d; color: #f8f8f2; font-family: consolas, monospace; }
        .back-btn { 
            display: inline-block; padding: 8px 16px; margin-bottom: 20px; 
            background: #61dafb; color: #000; text-decoration: none; border-radius: 4px; font-weight: bold;
        }
    </style>
</head>
<body>

    <a href="index.html" class="back-btn">← 返回目录</a>

    <pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

from ..base_model import BaseModel
from ..modules import SeparateFCs, BasicConv3d, PackSequenceWrapper, SeparateBNNecks


class GLConv(nn.Module):
    def __init__(self, in_channels, out_channels, halving, fm_sign=False, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False, **kwargs):
        super(GLConv, self).__init__()
        self.halving = halving
        self.fm_sign = fm_sign
        self.global_conv3d = BasicConv3d( # 全局分支
            in_channels, out_channels, kernel_size, stride, padding, bias, **kwargs)
        self.local_conv3d = BasicConv3d( # 局部分支 (共享权重)
            in_channels, out_channels, kernel_size, stride, padding, bias, **kwargs)

    def forward(self, x):
        '''
            x: [n, c, s, h, w]
        '''
        gob_feat = self.global_conv3d(x) # 全局特征提取
        # 局部特征提取 (切分->卷积->拼接)
        if self.halving == 0:
            lcl_feat = self.local_conv3d(x)
        else:
            h = x.size(3)
            split_size = int(h // 2**self.halving) # 计算切分大小
            lcl_feat = x.split(split_size, 3) # 在高度维度切分
            lcl_feat = torch.cat([self.local_conv3d(_) for _ in lcl_feat], 3) # 卷积后拼接

        # 特征融合 (GLConvA vs GLConvB)
        if not self.fm_sign:
            # GLConvA: 公式(2)，相加
            feat = F.leaky_relu(gob_feat) + F.leaky_relu(lcl_feat)
        else:
            # GLConvB: 公式(6)，拼接
            feat = F.leaky_relu(torch.cat([gob_feat, lcl_feat], dim=3))
        return feat

# 广义平均池化 (GeM Pooling)
# 1.将特征图水平切分为多个条带 (Bins)；2.对每个条带进行广义平均池化 (GeM Pooling)
class GeMHPP(nn.Module):
    def __init__(self, bin_num=[64], p=6.5, eps=1.0e-6):
        super(GeMHPP, self).__init__()
        self.bin_num = bin_num
        self.p = nn.Parameter(
            torch.ones(1)*p)
        self.eps = eps

    def gem(self, ipts):
        # 公式(8)
        return F.avg_pool2d(ipts.clamp(min=self.eps).pow(self.p), (1, ipts.size(-1))).pow(1. / self.p)

    def forward(self, x):
        """
            x  : [n, c, h, w]
            ret: [n, c, p] 
        """
        n, c = x.size()[:2]
        features = []
        for b in self.bin_num:
            z = x.view(n, c, b, -1)
            z = self.gem(z).squeeze(-1)
            features.append(z)
        return torch.cat(features, -1)

# Overall Architecture of GaitGL
class GaitGL(BaseModel):
    """
        GaitGL: Gait Recognition via Effective Global-Local Feature Representation and Local Temporal Aggregation
        Arxiv : https://arxiv.org/pdf/2011.01461.pdf
    """

    def __init__(self, *args, **kargs):
        super(GaitGL, self).__init__(*args, **kargs)

    def build_network(self, model_cfg):
        in_c = model_cfg['channels']
        class_num = model_cfg['class_num']
        dataset_name = self.cfgs['data_cfg']['dataset_name']

        if dataset_name in ['OUMVLP', 'GREW']:
            # For OUMVLP and GREW
            self.conv3d = nn.Sequential( 
                BasicConv3d(1, in_c[0], kernel_size=(3, 3, 3),
                            stride=(1, 1, 1), padding=(1, 1, 1)),
                nn.LeakyReLU(inplace=True),
                BasicConv3d(in_c[0], in_c[0], kernel_size=(3, 3, 3),
                            stride=(1, 1, 1), padding=(1, 1, 1)),
                nn.LeakyReLU(inplace=True),
            )
            self.LTA = nn.Sequential( 
                BasicConv3d(in_c[0], in_c[0], kernel_size=(
                    3, 1, 1), stride=(3, 1, 1), padding=(0, 0, 0)), # 时间维度T压缩3倍，保持高度H和宽度W不变
                nn.LeakyReLU(inplace=True)
            )

            
            self.GLConvA0 = nn.Sequential( # GLConvA: 结合全局和局部特征（相加模式），通道数变为C_1
                GLConv(in_c[0], in_c[1], halving=1, fm_sign=False, kernel_size=(
                    3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),
                GLConv(in_c[1], in_c[1], halving=1, fm_sign=False, kernel_size=(
                    3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),
            )
            self.MaxPool0 = nn.MaxPool3d( # 空间下采样，核大小 (1, 2, 2)，时间维度不变，空间减半
                kernel_size=(1, 2, 2), stride=(1, 2, 2))

            self.GLConvA1 = nn.Sequential( # 继续提取特征（相加模式）
                GLConv(in_c[1], in_c[2], halving=1, fm_sign=False, kernel_size=(
                    3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),
                GLConv(in_c[2], in_c[2], halving=1, fm_sign=False, kernel_size=(
                    3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),
            )
            self.GLConvB2 = nn.Sequential( # 最后一层使用拼接模式fm_sign=True，增加特征的丰富度
                GLConv(in_c[2], in_c[3], halving=1, fm_sign=False,  kernel_size=(
                    3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),
                GLConv(in_c[3], in_c[3], halving=1, fm_sign=True,  kernel_size=(
                    3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),
            )

        else:
            # For CASIA-B or other unstated datasets.
            self.conv3d = nn.Sequential(
                BasicConv3d(1, in_c[0], kernel_size=(3, 3, 3),
                            stride=(1, 1, 1), padding=(1, 1, 1)),
                nn.LeakyReLU(inplace=True)
            )
            self.LTA = nn.Sequential(
                BasicConv3d(in_c[0], in_c[0], kernel_size=(
                    3, 1, 1), stride=(3, 1, 1), padding=(0, 0, 0)),
                nn.LeakyReLU(inplace=True)
            )

            self.GLConvA0 = GLConv(in_c[0], in_c[1], halving=3, fm_sign=False, kernel_size=(
                3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            self.MaxPool0 = nn.MaxPool3d(
                kernel_size=(1, 2, 2), stride=(1, 2, 2))

            self.GLConvA1 = GLConv(in_c[1], in_c[2], halving=3, fm_sign=False, kernel_size=(
                3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            self.GLConvB2 = GLConv(in_c[2], in_c[2], halving=3, fm_sign=True,  kernel_size=(
                3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))

        # 将3D特征序列压扁为2D图像特征，消除时间维度S。
        self.TP = PackSequenceWrapper(torch.max) # 着时间维度(dim=2)进行最大池化。会根据真实的序列长度seqL进行操作，忽略Padding的零
        # 将空间特征(H/2, W/2)聚合为P个特征向量
        self.HPP = GeMHPP()

        self.Head0 = SeparateFCs(64, in_c[-1], in_c[-1]) # 为64个水平条带bin中的每一个创建独立的FC层，确保局部特征被独立映射

        # BNNecks 或 标准BN+FC: 生成用于Triplet Loss的embed和用于Softmax Loss的logits
        if 'SeparateBNNecks' in model_cfg.keys():
            self.BNNecks = SeparateBNNecks(**model_cfg['SeparateBNNecks'])
            self.Bn_head = False
        else:
            self.Bn = nn.BatchNorm1d(in_c[-1])
            self.Head1 = SeparateFCs(64, in_c[-1], class_num)
            self.Bn_head = True

    def forward(self, inputs):
        ipts, labs, _, _, seqL = inputs
        seqL = None if not self.training else seqL
        if not self.training and len(labs) != 1:
            raise ValueError(
                'The input size of each GPU must be 1 in testing mode, but got {}!'.format(len(labs)))
        sils = ipts[0].unsqueeze(1) # 增加灰度轮廓图序列的通道维度[n, 1, s, h, w]
        del ipts
        n, _, s, h, w = sils.size()
        if s < 3:
            repeat = 3 if s == 1 else 2 #  如果帧数过少(S<3)，重复帧以满足3D卷积需求
            sils = sils.repeat(1, 1, repeat, 1, 1)

        # 浅层特征提取
        outs = self.conv3d(sils) # [N, 1, S, H, W] → Conv3d → [N, C_0, S, H, W]
        # 局部时间聚合 (Local Temporal Aggregation) 
        outs = self.LTA(outs) # [N, C_0, S, H, W] → LTA → [N, C_0, S/3, H, W]

        # GLFE:全局与局部特征提取器 (由多个 GLConv 层堆叠而成)
        # GLConvA -> Max Pooling -> GLConvA -> GLConvB  
        outs = self.GLConvA0(outs)
        outs = self.MaxPool0(outs)
        # [N, C_0, S/3, H, W] → GLConv → [N, C_1, S/3, H, W] → MaxPool → [N, C_1, S/3, H/2, W/2]
  
        outs = self.GLConvA1(outs)
        outs = self.GLConvB2(outs)  # [n, c, s, h, w]
        # [N, C_1, S/3, H/2, W/2] → GLConvA/B → [N, C_final, S/3, H/2, W/2]
        # 此时，网络已经提取了深层的3D时空特征

        # Feature Mapping: 时间池化 (TP) + 广义平均池化 (GeM)
        outs = self.TP(outs, seqL=seqL, options={"dim": 2})[0] # [N, C_final, S/3, H/2, W/2] → TP → [N, C_final, H/2, W/2]
        outs = self.HPP(outs)  # [N, C_final, H/2, W/2] → GeM → [N, C_final, P]
        
        # Head: 独立全连接层 (Separate FCs) 用于分类
        gait = self.Head0(outs)  # [n, c, p]

        if self.Bn_head:  # Original GaitGL Head
            bnft = self.Bn(gait)  # [n, c, p]
            logi = self.Head1(bnft)  # [n, c, p]
            embed = bnft
        else:  # BNNechk as Head
            bnft, logi = self.BNNecks(gait)  # [n, c, p]
            embed = gait

        n, _, s, h, w = sils.size()
        retval = {
            'training_feat': {
                # Embeddings: [N, C_out, P](用于计算样本间距离)
                # Logits: [N, ClassNum, P](用于分类预测ID)
                'triplet': {'embeddings': embed, 'labels': labs},
                'softmax': {'logits': logi, 'labels': labs}
            },
            'visual_summary': {
                'image/sils': sils.view(n*s, 1, h, w)
            },
            'inference_feat': {
                'embeddings': embed
            }
        }
        return retval

    </code></pre>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</body>
</html>
